June 27, 2019

Recurrent NN:

1) Tokenizer:  to convert text to integers

Example here: https://towardsdatascience.com/multi-class-text-classification-with-lstm-1590bee1bd17

Another example of multi class text classification with cool bar graphs is here:
https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f

MAX_NB_WORDS = 50000
# Max number of words in each complaint.
MAX_SEQUENCE_LENGTH = 250
# This is fixed.
EMBEDDING_DIM = 100
tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!"#$%&()*+,-./:;<=>?@[\]^_`{|}~', lower=True)
tokenizer.fit_on_texts(df['Consumer complaint narrative'].values)
word_index = tokenizer.word_index
print('Found %s unique tokens.' % len(word_index))


2) Next, truncate and pad the sequences

X = tokenizer.texts_to_sequences(df['Consumer complaint narrative'].values)
X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)
print('Shape of data tensor:', X.shape)


3) Convert the pathogen labels into numbers using one-hot encoding.

4) Split data into training and test sets. 

5) Create a model which does the following:

   a) Create an embedded layer: This converts text into vectors and is more efficient than 1-hot encoding. 

    Keras Embedding documentation: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding

   This should be the 1st layer in the model. A very good explanation of embedding and its advantage over 1-hot encoding is given in https://towardsdatascience.com/deep-learning-4-embedding-layers-f9a02d55ac12.
   
   Here is an article about how embedding is done. The most common way of doing it is by using word-to-vector, which itself 
   involves neural networks. 
   https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa#targetText=Word%20embedding%20is%20one%20of,relation%20with%20other%20words%2C%20etc.&targetText=Loosely%20speaking%2C%20they%20are%20vector%20representations%20of%20a%20particular%20word.

   ‪model = Sequential()‬
‪model.add(Embedding(X, Y, Z))‬

X: size of the vocabulary. It is the max. # words to be used. For a 5-mer, it I 4^5 = 1024. 

Y: Dim. of the dense embedding. It is the length of the vector or the # latent factors. 

Z: input length. It is the length of the input sequence which is a constant after padding. For us, it will be 75 bp/5 for a 5-mer (I guess).
  
Here is an explanation of how embedding is better than 1-hot encoding when you have many “words”:

Suppose you have a 2-mer and a simple read which goes as AGTCGT. You can essentially consider it as a sentence made with 3 words, AG, TC, GT (because each word is a 2-mer). 

Now, for a 2-mer with 4 bases, there are only 4^2 = 16 possible combinations. We can refer to this as our “vocabulary” for the “words” that we are considering. Each word is represented as an integer, going from 1-16: 

AA 1
AC 2
AG 3
AT 4

CA 5
CC 6
CG 7
CT 8 and so on. 

So, the integer representation of the sentence [AG, TC, GT] is: [3, 14, 12]

Now, what happens here is that each integer is represented in a 10 dimensional space (each dim. is called a latent factor). 


   Integer    dim.1  dim.2. dim. 3  dim. 4.    
      1.        0.1.   0.9.   0.3.    0.5
      2.        0.9.   0.6.   0.2.    0.0
      3.        0.0.   0.1.   0.4.    0.7
      .
      .
      .
      16.       1.0.   1.0.   1.0.    0.9

(The #s for the latent factors are right now arbitrary but as the model gets trained, similar “words” get placed in similar regions in the 10 dim. space).

This is equivalent to 16X10 dimensional matrix. 

If we were using 1-hot encoding, we would have needed 16X16 matrix to reprent all “words”. So, as you can see, as we go to bigger k-mers, embedding becomes computationally more efficient and has an additional advantage of grouping similar words in the n-dimensional space. 




Additional notes:

1) Very helpful website to understand LSTM https://skymind.ai/wiki/lstm#long 

  Some precautions. Never make the # parameters in your model > # samples. That leads to over-fitting. Here are some links that give tricks to prevent over-fitting.  

#parameters  = [input_dim * # memory_cells + (#memory_cell)^2+#memory_cells)*4 ]

Where # memory cells are the # lstm cells in an last layer. It is the same as the number of units = dim. Of output space. 

Input dim is the dimensionality of the vector that represents a word. It is equal to the #latent factors in embedding. 

Some tricks (https://stats.stackexchange.com/questions/204745/preventing-overfitting-of-lstm-on-small-dataset) to prevent over-fitting:

   a) Keep # parameters < # instances.

   b) A rule of thumb is to keep # memory cells between # output classes and input_dim.

   c) Prefer stacking LSTM layers (i.e. deep NN) over increasing # memory cells in each LSTM layer. Deep NN give better results. 

Diagram showing how an LSTM layer looks and how to compute the corresponding number of parameters:
https://stats.stackexchange.com/questions/365428/difference-between-a-single-unit-lstm-and-3-unit-lstm-neural-network/365600#365600?newreg=f00e999a9937454e98ec70c2a5046239


2) http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/
Explains embedding and has some cool graphs.

3) https://www.tensorflow.org/tutorials/representation/word2vec
Example of how embedding clusters the “words” that capture some general semantic relationships e.g. gender, verb tense etc. 

4) GRU (Gated Recurrent Units) Vs. LSTM (Long Short Term Memory)

a) GRU: advantage: 

                Computationally faster since it has lesser gates. 
                 
b) GRU disadvantage: longer sentences do better with LSTM than with GRU. 

5) A very good example of a multi-text classification with 1 LSTM layer made of 100 memory cells:
https://towardsdatascience.com/multi-class-text-classification-with-lstm-1590bee1bd17

6) Step-by-step details to build an LSTM (including which packages to download) :

https://blog.goodaudience.com/first-experience-of-building-a-lstm-model-with-tensorflow-e632bde911e1


#########################
 7 August 2019
 #########################
 
 Notes on confusion matrix:
 
 you will have to convert one-hot encoded y_predicted_scores and y_test into integers. To do this, use np.argmax, because the index corresponding to '1' in the 1-hot encoded vectors gives the corresponding class in multiclass classification. 
 
 ```
 ytest_score = MyModel.model.predict(x_test) # for each instance, this spits out n scores,
                                             # where n is number of labels.

# Get the index of the highest score. That gives the corresponding predicted label (int)

y_predicted_label = (np.argmax(ytest_score, axis = 1)+1).reshape(-1,1)

# Get the index corresponding to '1' in 1-hot encoded y_test. That gives the
# corresponding true label (int).

y_true_label = (np.argmax(y_test, axis=1)+1).reshape(-1,1)


```

To plot the confusion matrix, 

```
    from sklearn.metrics import confusion_matrix
    import matplotlib.pyplot as plt
    from mlxtend.plotting import plot_confusion_matrix

    cm = confusion_matrix(y_true_label, y_predicted_label)

    fig, ax = plot_confusion_matrix(conf_mat=cm)
    #plt.matshow(cm, cmap=plt.cm.Greens)
    plt.xlabel('Predicted labels')
    plt.ylabel('True labels')
```

I mainly followed examples from this link: http://rasbt.github.io/mlxtend/user_guide/evaluate/confusion_matrix/

#############################
30 Aug 2019
#############################

1) How to deal with highly imbalanced datasets such as ours where almost 98% of the reads have no corresponding label.

https://towardsdatascience.com/sampling-techniques-for-extremely-imbalanced-data-part-i-under-sampling-a8dbc3d8d6d8#targetText=The%20definition%20of%20imbalanced%20data,order%20of%20100%20to%201.

basically use an undersampling technique that's already implemented in scikit learn, eg. random undersampling, k-means, nearmiss etc.
#############################
4 Sep 2019
#############################

Question: why is ROC of a random classifier a line y=x, instead of a point at (0.5, 0.5):

Answer is in Stackexchange for data science: https://datascience.stackexchange.com/questions/31872/auc-roc-of-a-random-classifier

Derivation: Here I derive the AUC of a random classifier on a dataset with an arbitrary class imbalance.

Assuming that there is a fraction 𝑥 of positive cases and a fraction 1−𝑥 of negative cases, and that our classifier consists of randomly assigning the positive class with probability 𝜌 and the negative class with probability 1−𝜌. The confusion matrix of a random classifier will have the following expected proportions
𝑇𝑃=𝜌𝑥
𝐹𝑃=𝜌(1−𝑥)
𝐹𝑁=(1−𝜌)𝑥
𝑇𝑁=(1−𝜌)(1−𝑥)
Then we calculate the True Positive Rate (sensitivity) and False Positive Rate (1-specificity) of our random classifier

𝑇𝑃𝑅=𝑇𝑃/(𝑇𝑃+𝐹𝑁)
=𝜌𝑥/[𝜌𝑥+(1−𝜌)𝑥]
=𝜌

𝐹𝑃𝑅=𝐹𝑃/(𝑇𝑁+𝐹𝑃)
=𝜌(1−𝑥)/[𝜌(1−𝑥)+(1−𝜌)(1−𝑥)]
=𝜌

So, TPR = FPR for a random classifier.

#############################
6 Sep 2019
#############################

Difference between an epoch and a batch. And what it means by validation loss per epoch.

Answer: When we perform mini-batch gradient descent, we basically input a batch of m randomly chosen data points to calculate the gradient of the loss function versus each parameter. This is repeated until we hit a total size of N which the full training dataset size (excluding the validation set).

E.g. if the training set is split into 800 training points and 200 validation points, and the batch size =50, then the computation will be as as follows:

choose random 50 points out of 800 ---> find the gradient using these data points & update the parameter (say theta) by doing:
                                        theta_new = theta_old - learning_rate*gradient
                                        
Repeat the above step 800/50 times. So, the theta parameter gets updated 800/50 = 18 times. After the 18th iteration, calculate the accuracy and the loss using the validation set. The validation set is NOT used to update the parameter. 

An epoch is when the the whole dataset finishes participating in training. Each epoch consists one 1 batch in case of simple gradient descent, or 800/50 batches in the above example, in case of mini-batch gradient descent.  

###########################
9 Sept 2019
###########################

Why precision-recall curves are better curves for evaluation than ROC, for imbalanced datasets?

1) https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/

Reviewing both precision and recall is useful in cases where there is an imbalance in the observations between the two classes. Specifically, there are many examples of no event (class 0) and only a few examples of an event (class 1).

The reason for this is that typically the large number of class 0 examples means we are less interested in the skill of the model at predicting class 0 correctly, e.g. high true negatives.

Key to the calculation of precision and recall is that the calculations do not make use of the true negatives. It is only concerned with the correct prediction of the minority class, class 1.


2)http://www.davidsbatista.net/blog/2018/08/19/NLP_Metrics/#targetText=Precision%2DRecall%20curve&targetText=ROC%20curves%20are%20appropriate%20when,are%20appropriate%20for%20imbalanced%20datasets.





